{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Describe the purpose and benefits of pooling in CNN.\n",
        "\n",
        "Pooling in Convolutional Neural Networks (CNNs) is used to reduce the spatial dimensions (width and height) of the input volume. This reduction is achieved through a pooling operation, which aggregates information over a region of the input feature map. The primary purposes and benefits of pooling include:\n",
        "\n",
        "- **Dimensionality Reduction**: Reduces the number of parameters and computations in the network, making it more efficient.\n",
        "- **Translation Invariance**: Helps the network become more robust to translations and distortions in the input.\n",
        "- **Control Overfitting**: By reducing the dimensionality, pooling can help prevent overfitting.\n",
        "\n",
        "### 2. Explain the difference between min pooling and max pooling\n",
        "\n",
        "- **Max Pooling**: Takes the maximum value within a defined pooling window. It emphasizes the most prominent features within the region, which can help highlight strong activations.\n",
        "  \n",
        "- **Min Pooling**: Takes the minimum value within a defined pooling window. It is less commonly used but can be beneficial in certain applications where the smallest features are of interest.\n",
        "\n",
        "### 3. Discuss the concept of padding in CNN and its significance.\n",
        "\n",
        "Padding in CNNs involves adding extra pixels to the border of an input image or feature map. The significance of padding includes:\n",
        "\n",
        "- **Control Output Size**: Padding helps control the spatial dimensions of the output feature maps.\n",
        "- **Preserve Information at Borders**: Ensures that edge pixels are considered during convolution, preserving information that might otherwise be lost.\n",
        "- **Maintain Spatial Dimensions**: In some cases, padding allows the input and output dimensions to remain the same, facilitating easier design of the network architecture.\n",
        "\n",
        "### 4. Compare and contrast zero-padding and valid-padding in terms of their effects on the output feature map size.\n",
        "\n",
        "- **Zero-padding**: Adds zeros to the border of the input. It increases the size of the input, allowing for more convolutions without shrinking the spatial dimensions. The output feature map size is the same as the input size when using a stride of 1.\n",
        "  \n",
        "- **Valid-padding**: No padding is added, meaning the convolution is only applied to valid regions of the input. The output feature map is smaller than the input, as edges are not padded and thus fewer convolutions can be performed.\n",
        "\n",
        "---\n",
        "\n",
        "### LeNet-5 Architecture\n",
        "\n",
        "#### 1. Provide a brief overview of LeNet-5 architecture.\n",
        "\n",
        "LeNet-5 is a pioneering Convolutional Neural Network (CNN) designed by Yann LeCun and others in 1998 for handwritten digit recognition (MNIST dataset). The architecture consists of seven layers (excluding the input), including convolutional layers, subsampling (pooling) layers, and fully connected layers.\n",
        "\n",
        "#### 2. Describe the key components of LeNet-5 and their respective purposes.\n",
        "\n",
        "- **Input Layer**: Takes a 32x32 pixel grayscale image.\n",
        "- **C1 (Convolutional Layer)**: Applies six 5x5 filters, resulting in a 28x28x6 output.\n",
        "- **S2 (Subsampling/Pooling Layer)**: Performs average pooling with a 2x2 filter, resulting in a 14x14x6 output.\n",
        "- **C3 (Convolutional Layer)**: Applies sixteen 5x5 filters, resulting in a 10x10x16 output.\n",
        "- **S4 (Subsampling/Pooling Layer)**: Performs average pooling with a 2x2 filter, resulting in a 5x5x16 output.\n",
        "- **C5 (Convolutional Layer)**: Applies 120 5x5 filters, resulting in a 1x1x120 output.\n",
        "- **F6 (Fully Connected Layer)**: 84 neurons, each connected to the previous layer.\n",
        "- **Output Layer**: 10 neurons (one for each digit), using softmax activation for classification.\n",
        "\n",
        "#### 3. Discuss the advantages and limitations of LeNet-5 in the context of image classification tasks.\n",
        "\n",
        "**Advantages**:\n",
        "- **Pioneering Design**: Demonstrated the effectiveness of CNNs for image classification.\n",
        "- **Efficiency**: Designed to be computationally efficient for the hardware available at the time.\n",
        "- **Good for Small Datasets**: Performs well on small-scale datasets like MNIST.\n",
        "\n",
        "**Limitations**:\n",
        "- **Limited Scalability**: Not suitable for larger and more complex datasets.\n",
        "- **Outdated Techniques**: Modern CNNs use more advanced techniques like ReLU activations, dropout for regularization, and batch normalization.\n",
        "\n",
        "### AlexNet Architecture\n",
        "\n",
        "#### 1. Present an overview of the AlexNet architecture.\n",
        "\n",
        "AlexNet is a deep convolutional neural network that won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012. It consists of five convolutional layers, followed by three fully connected layers, and uses ReLU activations and dropout for regularization.\n",
        "\n",
        "#### 2. Explain the architectural innovations introduced in AlexNet that contributed to its breakthrough performance.\n",
        "\n",
        "- **ReLU Activation**: Used ReLU activation functions instead of sigmoid or tanh, leading to faster training.\n",
        "- **Dropout**: Employed dropout in fully connected layers to reduce overfitting.\n",
        "- **Data Augmentation**: Applied data augmentation techniques like random cropping and flipping to increase the diversity of the training data.\n",
        "- **GPU Utilization**: Took advantage of GPU acceleration for training large-scale deep networks.\n",
        "\n",
        "#### 3. Discuss the role of convolutional layers, pooling layers, and fully connected layers in AlexNet.\n",
        "\n",
        "- **Convolutional Layers**: Extract features from the input images by applying convolutional filters.\n",
        "- **Pooling Layers**: Reduce the spatial dimensions of the feature maps, providing translation invariance and reducing the computational load.\n",
        "- **Fully Connected Layers**: Perform classification based on the extracted features from the convolutional and pooling layers.\n"
      ],
      "metadata": {
        "id": "usHq55ZhLdRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#### 4. Implement LeNet-5 using a deep learning framework of your choice (e.g., TensorFlow, PyTorch) and train it on a publicly available dataset (e.g., MNIST). Evaluate its performance and provide insights.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define LeNet-5 architecture\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.avg_pool2d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.avg_pool2d(x, 2)\n",
        "        x = x.view(-1, 16*4*4)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Data loading and preprocessing\n",
        "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LeNet5().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total}%')\n",
        "\n"
      ],
      "metadata": {
        "id": "9KopVd2HL2xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Implement AlexNet using a deep learning framework of your choice and evaluate its performance on a dataset of your choice.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define AlexNet architecture\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Data loading and preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = AlexNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # Print every 100 mini-batches\n",
        "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "id": "BY_LsafCL_5s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}